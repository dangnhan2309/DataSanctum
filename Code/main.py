from bertopic import BERTopic
from keybert import KeyBERT
from extractors import Extractor
from fileprocessor import FileProcessor
from nltk.corpus import stopwords
import re

# 1. Load m√¥ h√¨nh BERTopic ƒë√£ l∆∞u
def load_topic_model(model_path):
    try:
        model = BERTopic.load(model_path)
        print(f"‚úÖ ƒê√£ load BERTopic model t·ª´: {model_path}")
        return model
    except Exception as e:
        import traceback
        print("‚ùå L·ªói khi load model:")
        traceback.print_exc()  # In to√†n b·ªô stack trace
        return None

# 2. X√°c ƒë·ªãnh lo·∫°i file v√† h√†m extractor
def detect_file_type_and_extractor(file_path, file_processor):
    result = file_processor.process_file(file_path)
    if result is None:
        print("‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω file. D·ª´ng pipeline.")
        return None
    mime_type, extractor_func_name = result
    print(f"[‚Ñπ] MIME Type: {mime_type}")
    print(f"[‚Ñπ] Extractor: {extractor_func_name}")
    
    if mime_type not in ['application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'application/pdf']:
        print("‚ö† Kh√¥ng x√°c ƒë·ªãnh MIME type h·ª£p l·ªá.")
        return None
    
    return extractor_func_name

# 3. L√†m s·∫°ch vƒÉn b·∫£n
def clean_text_remove_stopwords(text):
    stop_words = set(stopwords.words('english') + ['http', 'https', 'amp', 'com'])
    words = re.findall(r'\b\w+\b', text.lower())
    filtered = [word for word in words if word not in stop_words]
    return ' '.join(filtered)

# 4. Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file
def extract_text(file_path, extractor_func_name, extractor):
    extractor_func = getattr(extractor, extractor_func_name, None)
    if extractor_func:
        text = extractor_func(file_path)
        print(f"üìë ƒê√£ tr√≠ch xu·∫•t {len(text)} k√Ω t·ª± t·ª´ file.")
        cleaned_text = clean_text_remove_stopwords(text)
        print(f"‚úÖ VƒÉn b·∫£n sau khi lo·∫°i b·ªè stopwords: {len(cleaned_text)} k√Ω t·ª±.")
        return cleaned_text
    else:
        print(f"‚ö† Kh√¥ng t√¨m th·∫•y h√†m extractor: {extractor_func_name}")
        return None

# 5. D·ª± ƒëo√°n ch·ªß ƒë·ªÅ
def predict_topic(text, topic_model):
    topics, probs = topic_model.transform([text])
    if topics[0] == -1:
        print("‚ö† Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ch·ªß ƒë·ªÅ.")
        return None
    topic_id = topics[0]
    topic_words = topic_model.get_topic(topic_id)
    topic_words_list = [word for word, _ in topic_words[:15]]
    confidence = probs[0].max()
    return topic_id, topic_words_list, confidence

# 6. T·∫°o t√™n ch·ªß ƒë·ªÅ
def generate_topic_name(topic_words):
    kw_model = KeyBERT(model="all-MiniLM-L6-v2")
    text = " ".join(topic_words)
    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 3), stop_words='english', top_n=1)
    return keywords[0][0].title() if keywords else "Unnamed Topic"

# 7. Hi·ªÉn th·ªã th√¥ng tin ch·ªß ƒë·ªÅ
def display_topic_info(topic_id, topic_words, confidence, topic_name):
    print("\nüéØ Ch·ªß ƒë·ªÅ d·ª± ƒëo√°n")
    print("-" * 50)
    print(f"üÜî ID: {topic_id}")
    print(f"üîç T√™n: {topic_name}")
    print(f"üí° T·ª´ kh√≥a: {', '.join(topic_words)}")
    print(f"üìà ƒê·ªô tin c·∫≠y: {confidence:.4f}")
    print("-" * 50)

# 8. Pipeline ch√≠nh
def process_file_for_topic(file_path, model_path):
    topic_model = load_topic_model(model_path)
    if not topic_model:
        return

    file_processor = FileProcessor()
    extractor = Extractor()

    extractor_func_name = detect_file_type_and_extractor(file_path, file_processor)
    if not extractor_func_name:
        return

    text = extract_text(file_path, extractor_func_name, extractor)
    if not text:
        print("‚ùå Kh√¥ng c√≥ vƒÉn b·∫£n ƒë·ªÉ ph√¢n t√≠ch.")
        return

    result = predict_topic(text, topic_model)
    if not result:
        return
    topic_id, topic_words, confidence = result
    topic_name = generate_topic_name(topic_words)

    display_topic_info(topic_id, topic_words, confidence, topic_name)

# 9. H√†m main
def main():
    file_path = r"D:\DST\support\Tool\material\O.docx"
    model_path = r"D:\model\bertopic_model(ver4-50k_Reference)"
    process_file_for_topic(file_path, model_path)

if __name__ == "__main__":
    main()
